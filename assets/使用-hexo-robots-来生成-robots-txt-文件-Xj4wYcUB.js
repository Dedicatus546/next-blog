import{createElementBlock as t,openBlock as n,createStaticVNode as e}from"vue";import{c as p}from"./app-C7bQa6bS.js";import"nprogress";import"pinia-plugin-persistedstate";import"vue-router";import"vue-router-better-scroller";import"@vueuse/core";import"@vueuse/components";import"@vueuse/router";import"octokit";import"pinia";import"date-fns";const l={class:"kan-doc"},u="使用 hexo-robots 来生成 robots.txt 文件",C=["hexo","robots.txt"],_=["编程"],v=1722567967,w="2024-08-02T10:32:54.000Z",E="2024-08-02T11:12:40.000Z",q=1834,j=[{property:"og:title",content:"使用 hexo-robots 来生成 robots.txt 文件"},{name:"twitter:title",content:"使用 hexo-robots 来生成 robots.txt 文件"}],T={__name:"使用-hexo-robots-来生成-robots-txt-文件",setup(o,{expose:a}){return a({frontmatter:{title:"使用 hexo-robots 来生成 robots.txt 文件",tags:["hexo","robots.txt"],categories:["编程"],key:1722567967,date:"2024-08-02T10:32:54.000Z",updated:"2024-08-02T11:12:40.000Z",wordCount:1834,meta:[{property:"og:title",content:"使用 hexo-robots 来生成 robots.txt 文件"},{name:"twitter:title",content:"使用 hexo-robots 来生成 robots.txt 文件"}]}}),p({title:"使用 hexo-robots 来生成 robots.txt 文件",meta:[{property:"og:title",content:"使用 hexo-robots 来生成 robots.txt 文件"},{name:"twitter:title",content:"使用 hexo-robots 来生成 robots.txt 文件"}]}),(d,s)=>(n(),t("div",l,s[0]||(s[0]=[e(`<h1 id="前言" tabindex="-1">前言 <a class="header-anchor" href="#前言">🔗</a></h1><p>使用 hexo-robots 来生成 robots.txt 文件</p><h1 id="正文" tabindex="-1">正文 <a class="header-anchor" href="#正文">🔗</a></h1><p>对于一个静态网站来说，在被搜索引擎收录的过程中，会有很多的来自爬虫程序请求，但某些文件没有被爬取的必要，比如 js 文件、 css 文件、图片文件等等。 robots.txt 可以通过声明来让爬虫程序忽略某些文件。</p><p>相关的定义可以查看 Google 关于 robots.txt 的解释：<a href="https://developers.google.com/search/docs/crawling-indexing/robots/intro?hl=zh-cn" target="_blank" rel="noopener">robots.txt 简介</a>。</p><p>对于 hexo 来讲，在不使用其他任何辅助工具的情况下，可以直接在 <code>_posts</code> 中创建一个 robots.txt 文件，向里面编写内容即可。</p><p>这里要注意，如果未将 robots.txt 文件写入配置中的 <code>skip_render</code> 情况下，需要在头部声明 <code>layout: false</code> ，不然会生成 html 标签，造成 robots.txt 无效</p><pre class="shiki shiki-themes vitesse-dark vitesse-light" style="--s-dark:#dbd7caee;--s-light:#393a34;--s-dark-bg:#121212;--s-light-bg:#ffffff;" tabindex="0"><code class="language-text"><span class="line"><span>---</span></span>
<span class="line"><span>layout: false</span></span>
<span class="line"><span>---</span></span>
<span class="line"><span></span></span>
<span class="line"><span># 主体代码</span></span>
<span class="line"><span># ...</span></span></code></pre><p>这样配置之后，生成的 robots.txt 就是单纯的从 <code>source/_posts</code> 拷贝到输出目录中，但还有一个问题就是 <code>layout: false</code> 这一段并不会被删掉</p><p>这可能会导致搜索引擎在解析 robots.txt 的时候会报错，比如 Google Search Console 中：</p><p><a data-fancybox="doc-gallery" href="https://fastly.jsdelivr.net/gh/Dedicatus546/image@main/2024/08/02/20240802021525284.avif" target="_blank" rel="noopener noreferrer"><img src="https://fastly.jsdelivr.net/gh/Dedicatus546/image@main/2024/08/02/20240802021525284.avif" alt=""></a></p><p>所以我们可以去掉这个 <code>layout: false</code> ，然后把 robots.txt 加到 <code>skip_render</code> 配置中：</p><pre class="shiki shiki-themes vitesse-dark vitesse-light" style="--s-dark:#dbd7caee;--s-light:#393a34;--s-dark-bg:#121212;--s-light-bg:#ffffff;" tabindex="0"><code class="language-yml"><span class="line"><span style="--s-dark:#758575DD;--s-light:#A0ADA0;"># _config.yml</span></span>
<span class="line"></span>
<span class="line"><span style="--s-dark:#B8A965;--s-light:#998418;">skip_render</span><span style="--s-dark:#666666;--s-light:#999999;">:</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> _posts/robots.txt</span></span></code></pre><p>其实这样基本就可以了。</p><p>但是作为一个喜欢没事找事干的老孩，这不得用一个插件来实现实在是说不过去。</p><h2 id="hexo-robots" tabindex="-1">hexo-robots <a class="header-anchor" href="#hexo-robots">🔗</a></h2><p>综上所属，我编写了一个 <a href="https://github.com/Dedicatus546/hexo-robots" target="_blank" rel="noopener">hexo-robots</a> 的插件，只需要在 <code>_config.yml</code> 添加相应的配置即可生成相应的 robots.txt 文件。</p><p>先安装 hexo-robots 这个包</p><pre class="shiki shiki-themes vitesse-dark vitesse-light" style="--s-dark:#dbd7caee;--s-light:#393a34;--s-dark-bg:#121212;--s-light-bg:#ffffff;" tabindex="0"><code class="language-shell"><span class="line"><span style="--s-dark:#80A665;--s-light:#59873A;">npm</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> install</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> hexo-robots</span></span></code></pre><p>接着在 <code>_config.yml</code> 添加如下配置：</p><pre class="shiki shiki-themes vitesse-dark vitesse-light" style="--s-dark:#dbd7caee;--s-light:#393a34;--s-dark-bg:#121212;--s-light-bg:#ffffff;" tabindex="0"><code class="language-yml"><span class="line"><span style="--s-dark:#B8A965;--s-light:#998418;">robots</span><span style="--s-dark:#666666;--s-light:#999999;">:</span></span>
<span class="line"><span style="--s-dark:#B8A965;--s-light:#998418;">  user_agent</span><span style="--s-dark:#666666;--s-light:#999999;">:</span><span style="--s-dark:#C98A7D77;--s-light:#B5695977;"> &quot;</span><span style="--s-dark:#C98A7D;--s-light:#B56959;">*</span><span style="--s-dark:#C98A7D77;--s-light:#B5695977;">&quot;</span><span style="--s-dark:#758575DD;--s-light:#A0ADA0;">   # 如果要写通配符，请务必要加上双引号，不然解析会报错</span></span>
<span class="line"><span style="--s-dark:#B8A965;--s-light:#998418;">  allow</span><span style="--s-dark:#666666;--s-light:#999999;">:</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">    -</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> /</span><span style="--s-dark:#DBD7CAEE;--s-light:#393A34;"> </span></span>
<span class="line"><span style="--s-dark:#B8A965;--s-light:#998418;">  disallow</span><span style="--s-dark:#666666;--s-light:#999999;">:</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">    -</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> /js/</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">    -</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> /css/</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">    -</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> /images/</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">    -</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> /archives/</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">    -</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> /page/</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">    -</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> /schedule/</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">    -</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> /tags/</span></span>
<span class="line"><span style="--s-dark:#B8A965;--s-light:#998418;">  sitemaps</span><span style="--s-dark:#666666;--s-light:#999999;">:</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">    -</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> https://prohibitorum.top/sitemap.xml</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">    -</span><span style="--s-dark:#C98A7D;--s-light:#B56959;"> https://prohibitorum.top/baidusitemap.xml</span></span></code></pre><p>上面的就是目前该网站所使用 robots.txt 。</p><h1 id="后记" tabindex="-1">后记 <a class="header-anchor" href="#后记">🔗</a></h1><p>该插件的核心是为 hexo 注册一个 generator 。它的形式看起来如下：</p><pre class="shiki shiki-themes vitesse-dark vitesse-light" style="--s-dark:#dbd7caee;--s-light:#393a34;--s-dark-bg:#121212;--s-light-bg:#ffffff;" tabindex="0"><code class="language-typescript"><span class="line"><span style="--s-dark:#BD976A;--s-light:#B07D48;">hexo</span><span style="--s-dark:#666666;--s-light:#999999;">.</span><span style="--s-dark:#BD976A;--s-light:#B07D48;">extend</span><span style="--s-dark:#666666;--s-light:#999999;">.</span><span style="--s-dark:#BD976A;--s-light:#B07D48;">generator</span><span style="--s-dark:#666666;--s-light:#999999;">.</span><span style="--s-dark:#80A665;--s-light:#59873A;">register</span><span style="--s-dark:#666666;--s-light:#999999;">(</span><span style="--s-dark:#BD976A;--s-light:#B07D48;">name</span><span style="--s-dark:#666666;--s-light:#999999;">,</span><span style="--s-dark:#CB7676;--s-light:#AB5959;"> function</span><span style="--s-dark:#666666;--s-light:#999999;"> (</span><span style="--s-dark:#BD976A;--s-light:#B07D48;">locals</span><span style="--s-dark:#666666;--s-light:#999999;">)</span><span style="--s-dark:#666666;--s-light:#999999;"> {</span></span>
<span class="line"><span style="--s-dark:#DBD7CAEE;--s-light:#393A34;">  </span></span>
<span class="line"><span style="--s-dark:#758575DD;--s-light:#A0ADA0;">    // 如何生成 data 的逻辑</span></span>
<span class="line"><span style="--s-dark:#DBD7CAEE;--s-light:#393A34;">    </span></span>
<span class="line"><span style="--s-dark:#4D9375;--s-light:#1E754F;">    return</span><span style="--s-dark:#666666;--s-light:#999999;"> {</span></span>
<span class="line"><span style="--s-dark:#B8A965;--s-light:#998418;">        path</span><span style="--s-dark:#666666;--s-light:#999999;">: </span><span style="--s-dark:#C98A7D77;--s-light:#B5695977;">&quot;</span><span style="--s-dark:#C98A7D;--s-light:#B56959;">robots.txt</span><span style="--s-dark:#C98A7D77;--s-light:#B5695977;">&quot;</span><span style="--s-dark:#666666;--s-light:#999999;">,</span></span>
<span class="line"><span style="--s-dark:#B8A965;--s-light:#998418;">        data</span><span style="--s-dark:#666666;--s-light:#999999;">: </span><span style="--s-dark:#C98A7D77;--s-light:#B5695977;">&quot;</span><span style="--s-dark:#C98A7D;--s-light:#B56959;">{{文件内容}}</span><span style="--s-dark:#C98A7D77;--s-light:#B5695977;">&quot;</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">    }</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">});</span></span></code></pre>`,25)])))}};export{_ as categories,w as date,T as default,v as key,j as meta,C as tags,u as title,E as updated,q as wordCount};
