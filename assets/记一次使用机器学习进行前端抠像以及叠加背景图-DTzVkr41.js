import{createElementBlock as a,openBlock as t,createStaticVNode as o}from"vue";import{c as p}from"./app-CGnJzz9B.js";import"nprogress";import"pinia-plugin-persistedstate";import"vue-router";import"vue-router-better-scroller";import"@vueuse/core";import"@vueuse/components";import"@vueuse/router";import"octokit";import"pinia";import"date-fns";const n={class:"kan-doc"},b="记一次使用机器学习进行前端抠像以及叠加背景图",B=["抠像","canvas","机器学习"],S=["编程"],_=1668138263,j="2022-11-11T11:44:23.000Z",x="2023-02-13T18:28:45.000Z",w=3891,E=[{property:"og:title",content:"记一次使用机器学习进行前端抠像以及叠加背景图"},{name:"twitter:title",content:"记一次使用机器学习进行前端抠像以及叠加背景图"}],T={__name:"记一次使用机器学习进行前端抠像以及叠加背景图",setup(d,{expose:s}){return s({frontmatter:{title:"记一次使用机器学习进行前端抠像以及叠加背景图",tags:["抠像","canvas","机器学习"],categories:["编程"],key:1668138263,date:"2022-11-11T11:44:23.000Z",updated:"2023-02-13T18:28:45.000Z",wordCount:3891,meta:[{property:"og:title",content:"记一次使用机器学习进行前端抠像以及叠加背景图"},{name:"twitter:title",content:"记一次使用机器学习进行前端抠像以及叠加背景图"}]}}),p({title:"记一次使用机器学习进行前端抠像以及叠加背景图",meta:[{property:"og:title",content:"记一次使用机器学习进行前端抠像以及叠加背景图"},{name:"twitter:title",content:"记一次使用机器学习进行前端抠像以及叠加背景图"}]}),(l,e)=>(t(),a("div",n,e[0]||(e[0]=[o(`<h1 id="前言" tabindex="-1">前言 <a class="header-anchor" href="#前言">🔗</a></h1><p>感觉好久没写帖子了，那篇 <code>10</code> 月的新番推荐现在还躺在我的草稿列表里面😂</p><p>双十一花了点钱搞了台主机，本以为现在终于可以不用背电脑上下班了，没想到来了疫情，不来回背等下工作就要没了…</p><p>刚好最近公司要我搞一个前端抠像的 <code>demo</code> ，给了我一些资料，觉得挺有意思，所以来写写</p><p>至于标题的机器学习，我只是一个合格的 <code>api</code> 调用，切图工程师，不写机器学习怎么能引诱你进来看？</p><h1 id="正文" tabindex="-1">正文 <a class="header-anchor" href="#正文">🔗</a></h1><p>这次我们使用的是谷歌的一个机器学习库 <code>MediaPipe Selfie Segmentation</code></p><p>官方文档地址 <a href="https://google.github.io/mediapipe/solutions/selfie_segmentation" target="_blank" rel="noopener">MediaPipe Selfie Segmentation</a></p><p>当然，怎么实现我肯定是不懂的，但是提供了 <code>api</code> ，我们可以为此写出一个差不多的 <code>demo</code> ，然后去给客户演示“赚”资金</p><p>翻到 <code>javascript-solution-api</code> 标题，就可以看到 <code>js</code> 下的 <code>api</code> 了，官方还很贴心的给了一个 <code>demo</code></p><p>当然，这里它额外用了一些其他的库 <code>drawing_utils</code> ，<code> camera_utils</code> 以及 <code>control_utils</code></p><p>看起来都是一些工具库，但在我们的 <code>demo</code> 中不会用到这些库</p><p><img src="https://fastly.jsdelivr.net/gh/Dedicatus546/image@main/2022/11/10/202211101107850.avif" alt=""></p><p>这个 <code>demo</code> 主要流程为</p><ul><li>获取摄像头的流</li><li>抠像叠背景处理</li><li>导出一个处理过后的流</li></ul><p>首先我们要安装依赖，执行 <code>pnpm add @mediapipe/selfie_segmentation</code></p><p>然后我们要到 <code>node_modules</code> 下找到这个包，把除了 <code>selfie_segmentation.js</code> 文件之外的其他文件放到 <code>public</code> 文件夹下（这里我使用的是 <code>vite</code> 创建的 <code>react</code> 项目）</p><p><img src="https://fastly.jsdelivr.net/gh/Dedicatus546/image@main/2022/11/10/202211101636174.avif" alt=""></p><p>放到 <code>public</code> 文件夹中</p><p><img src="https://fastly.jsdelivr.net/gh/Dedicatus546/image@main/2022/11/10/202211101640356.avif" alt=""></p><p>然后我们用下面的代码就可以初始化一个对象</p><pre class="shiki shiki-themes vitesse-dark vitesse-light" style="--s-dark:#dbd7caee;--s-light:#393a34;--s-dark-bg:#121212;--s-light-bg:#ffffff;" tabindex="0"><code class="language-javascript"><span class="line"><span style="--s-dark:#4D9375;--s-light:#1E754F;">import</span><span style="--s-dark:#666666;--s-light:#999999;"> {</span><span style="--s-dark:#BD976A;--s-light:#B07D48;"> SelfieSegmentation</span><span style="--s-dark:#666666;--s-light:#999999;"> }</span><span style="--s-dark:#4D9375;--s-light:#1E754F;"> from</span><span style="--s-dark:#C98A7D77;--s-light:#B5695977;"> &quot;</span><span style="--s-dark:#C98A7D;--s-light:#B56959;">@mediapipe/selfie_segmentation</span><span style="--s-dark:#C98A7D77;--s-light:#B5695977;">&quot;</span><span style="--s-dark:#666666;--s-light:#999999;">;</span></span>
<span class="line"></span>
<span class="line"><span style="--s-dark:#CB7676;--s-light:#AB5959;">const</span><span style="--s-dark:#BD976A;--s-light:#B07D48;"> selfieSegmentation</span><span style="--s-dark:#666666;--s-light:#999999;"> =</span><span style="--s-dark:#CB7676;--s-light:#AB5959;"> new</span><span style="--s-dark:#80A665;--s-light:#59873A;"> SelfieSegmentation</span><span style="--s-dark:#666666;--s-light:#999999;">({</span></span>
<span class="line"><span style="--s-dark:#758575DD;--s-light:#A0ADA0;">  // 这里的意思就是需要的文件从哪里获取</span></span>
<span class="line"><span style="--s-dark:#758575DD;--s-light:#A0ADA0;">  // 由于我们放到 public 下了，直接绝对路径 / 即可</span></span>
<span class="line"><span style="--s-dark:#80A665;--s-light:#59873A;">  locateFile</span><span style="--s-dark:#666666;--s-light:#999999;">:</span><span style="--s-dark:#666666;--s-light:#999999;"> (</span><span style="--s-dark:#BD976A;--s-light:#B07D48;">file</span><span style="--s-dark:#666666;--s-light:#999999;">)</span><span style="--s-dark:#666666;--s-light:#999999;"> =&gt;</span><span style="--s-dark:#666666;--s-light:#999999;"> {</span></span>
<span class="line"><span style="--s-dark:#4D9375;--s-light:#1E754F;">    return</span><span style="--s-dark:#C98A7D77;--s-light:#B5695977;"> \`</span><span style="--s-dark:#C98A7D;--s-light:#B56959;">/</span><span style="--s-dark:#4D9375;--s-light:#1E754F;">\${</span><span style="--s-dark:#C98A7D;--s-light:#B56959;">file</span><span style="--s-dark:#4D9375;--s-light:#1E754F;">}</span><span style="--s-dark:#C98A7D77;--s-light:#B5695977;">\`</span><span style="--s-dark:#666666;--s-light:#999999;">;</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">  },</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">});</span></span>
<span class="line"></span>
<span class="line"><span style="--s-dark:#758575DD;--s-light:#A0ADA0;">// 设置为 landscape 模型</span></span>
<span class="line"><span style="--s-dark:#BD976A;--s-light:#B07D48;">selfieSegmentation</span><span style="--s-dark:#666666;--s-light:#999999;">.</span><span style="--s-dark:#80A665;--s-light:#59873A;">setOptions</span><span style="--s-dark:#666666;--s-light:#999999;">({</span></span>
<span class="line"><span style="--s-dark:#B8A965;--s-light:#998418;">  modelSelection</span><span style="--s-dark:#666666;--s-light:#999999;">:</span><span style="--s-dark:#4C9A91;--s-light:#2F798A;"> 1</span><span style="--s-dark:#666666;--s-light:#999999;">,</span></span>
<span class="line"><span style="--s-dark:#666666;--s-light:#999999;">});</span></span></code></pre><p>这里的 <code>modelSelection</code> 可填的值有两个，分为为 <code>0</code> 和 <code>1</code></p><p>其中 <code>0</code> 代表 <code>general</code> 模型， <code>1</code> 代表 <code>landscape</code> 模型，默认是 <code>0</code></p><p>我们只需要知道这两个模型都是基于 <code>MobileNetV3</code> 模型而来，并且 <code>landscape</code> 模型比 <code>general</code> 模型快即可</p><p>文档中的相关解释</p><p><img src="https://fastly.jsdelivr.net/gh/Dedicatus546/image@main/2022/11/10/202211101648803.avif" alt=""></p><p>接着我们随手写一个 <code>UI</code> ，主要有设备的选择，以及把流喂给 <code>selfieSegmentation</code> 产生结果画到 <code>canvas</code> 上，以及 <code>canvas</code> 转 <code>mediaStream</code> 再喂给 <code>video</code> 标签</p><p>代码我就不贴了，搞得版面不是很好看，丢仓库里了，地址 <a href="https://github.com/Dedicatus546/mediaPipe-selfie-segmentation-demo" target="_blank" rel="noopener">Dedicatus546 / mediaPipe-selfie-segmentation-demo</a></p><p>跑起来之后我们就能看到如下界面</p><p><img src="https://fastly.jsdelivr.net/gh/Dedicatus546/image@main/2022/11/10/202211101825393.avif" alt=""></p><p>傻瓜式操作，选择设备，就会自动开启抠像了，选择图片，那么图片就会自动应用到抠像中，效果如下</p><p><img src="https://fastly.jsdelivr.net/gh/Dedicatus546/image@main/2022/11/11/202211111045742.avif" alt=""></p><p>看起来效果还是挺不错的，但是对手的支持就不是很理想了，在我这台 <code>i7-7700HQ</code> 上吃的性能还是挺多的，风扇一直在叫</p><p>这东西我也看了网上的其他文章，大部分到最后都是要服务端来抠像的，一方面兼容性有保证，一方面不会因为性能不足而导致抠像效果不佳</p><p>坏处就是需要更多的服务器资源了，也就意味着更多的钱钱</p><p>这里讲一下几个有趣的点</p><p>首先是 <code>canvas</code> 转 <code>mediaStream</code> ，刚开始其实我也不知道要怎么办，因为官方的文档其实只是画到 <code>canvas</code> 上而已</p><p>而我司的项目是要通过 <code>webRTC</code> 上传 <code>mediaStream</code> 的，这就很操蛋</p><p>然后我就找啊找，终于找到了一个实验性质的 <code>api</code> <a href="https://developer.mozilla.org/zh-CN/docs/Web/API/HTMLCanvasElement/captureStream" target="_blank" rel="noopener">HTMLCanvasElement.captureStream</a></p><p>调用这个 <code>api</code> ，我们就能直接拿到一个 <code>mediaStream</code> 流，当然，这个 <code>api</code> 目前兼容性较低</p><p><img src="https://fastly.jsdelivr.net/gh/Dedicatus546/image@main/2022/11/10/202211101830577.avif" alt=""></p><p>而且我看现在有提案好像是说要为每一个 <code>HTMLElement</code> 都添加一个 <code>captureStream</code> 方法，来生成视频流，这就非常的有趣好吧</p><p>另一个是关于 <code>canvas</code> 的 <code>2d</code> 上下文下的 <code>globalCompositeOperation</code> 属性，即 <code>CanvasRenderingContext2D.globalCompositeOperation</code></p><p>这个属性是能够在 <code>canvas</code> 上正确画出抠像的核心，<code>MDN</code> 文档地址：<a href="https://developer.mozilla.org/zh-CN/docs/Web/API/CanvasRenderingContext2D/globalCompositeOperation" target="_blank" rel="noopener">CanvasRenderingContext2D.globalCompositeOperation</a></p><p>在默认情况下，这个值为 <code>source-over</code> ，即哪里都可以画</p><p>我们需要把它设置为 <code>source-in</code> ，即新画的的东西只能画在画布上已绘制的区域，也就是两者取交集</p><p>在经过抠像之后，会生成两个图片，一个是当前帧的图片，一个是当前帧对应抠像的一个遮罩</p><p>这时我们先画遮罩，然后把 <code>globalCompositeOperation</code> 设为 <code>source-in</code> ，接下来画当前帧，那么就只能画在遮罩内了，而遮罩外就是透明的，从而完成抠像</p><p>在 <code>demo</code> 中，我使用了两个 <code>canvas</code> 来完成抠像和背景的叠加，我也尝试过使用单个 <code>canvas</code> ，但最终都失败了</p><p>我的思路是这样的，先绘制遮罩，然后设为 <code>source-in</code> ，再绘制视频帧，那么现在抠像就完成了，接着设置为 <code>source-out</code> ，绘制背景，此时我个人是认为背景是能绘制上去的</p><p>事实上也是如此，但是此时的抠像部分就变成透明了，这应该是 <code>globalCompositeOperation</code> 的特性，在 <code>source-in</code> 和 <code>source-out</code> 下，非绘制的部分都会变得透明</p><p>所以最终就使用了两个 <code>canvas</code> ，其中使用一个临时的 <code>canvas</code> 完成抠像，在主 <code>canvas</code> 上绘制背景，再绘制抠像的 <code>canvas</code> ，这样就可以实现叠加背景的效果</p><h1 id="后记" tabindex="-1">后记 <a class="header-anchor" href="#后记">🔗</a></h1><p>尝试使用了 <code>worker</code> 来接管某些过程，但是都失败了…</p>`,55)])))}};export{S as categories,j as date,T as default,_ as key,E as meta,B as tags,b as title,x as updated,w as wordCount};
